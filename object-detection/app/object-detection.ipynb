{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "\"As I explained before: you have to do detection with py-faster-rcnn and then a tracking using deep sort.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use mask-r-cnn to get detections in ROI format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"nba-images\")\n",
    "\n",
    "########################################\n",
    "\n",
    "\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "\n",
    "\"\"\"Create Model and Load Trained Weights\"\"\"\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "\n",
    "# class_names = ['person']\n",
    "\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "\n",
    "# Load a random image from the images folder\n",
    "file_names = next(os.walk(IMAGE_DIR))[2]\n",
    "image = skimage.io.imread(os.path.join(IMAGE_DIR, random.choice(file_names)))\n",
    "\n",
    "# Run detection\n",
    "results = model.detect([image], verbose=1)\n",
    "\n",
    "# Visualize results\n",
    "r = results[0]\n",
    "print(r['rois'].shape)\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import generate_detections\n",
    "from deep_sort.detection import Detection\n",
    "\n",
    "DEEP_SORT_DIR = 'deep_sort'\n",
    "MASKRCNN_DIR = 'maskrcnn'\n",
    "TEST_IMG = 'maskrcnn/nba-images/frame_000009.jpg'\n",
    "\n",
    "CHECKPOINT_PATH = os.path.join(DEEP_SORT_DIR, \"checkpoint\", \"mars-small128.ckpt-68577\")\n",
    "\n",
    "def main():\n",
    "    # Start up your application, then generate the encoder function.\n",
    "    encoder = generate_detections.create_box_encoder(CHECKPOINT_PATH)\n",
    "\n",
    "    # Now, enter the application main loop. Should be something like this:\n",
    "    for image, detections in my_data_source:\n",
    "        # - image is a BGR color image\n",
    "        # - detections is an Nx4 matrix of bounding boxes in\n",
    "        #   format (x, y, w, h) where (x, y) is the top-left corner\n",
    "        #   and (w, h) is the extent\n",
    "        # - features is an Nx128 matrix of corresponding appearance descriptors\n",
    "        features = encoder(image, detections)\n",
    "        \n",
    "        # Generate a list of detections (we simply set the confidence\n",
    "        # score to 1.0 here).\n",
    "        detections = [\n",
    "            Detection(bbox, 1.0, feature) for bbox, feature in\n",
    "            zip(detections, features)]\n",
    "\n",
    "        # Call the tracker\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "\n",
    "        # Go on and visualize the results, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import generate_detections\n",
    "from deep_sort.detection import Detection\n",
    "\n",
    "DEEP_SORT_DIR = 'deep_sort'\n",
    "MASKRCNN_DIR = 'maskrcnn'\n",
    "\n",
    "CHECKPOINT_PATH = os.path.join(DEEP_SORT_DIR, \"checkpoint\", \"mars-small128.ckpt-68577\")\n",
    "\n",
    "def main():\n",
    "    # Start up your application, then generate the encoder function.\n",
    "    encoder = generate_detections.create_box_encoder(CHECKPOINT_PATH)\n",
    "\n",
    "    # Now, enter the application main loop. Should be something like this:\n",
    "    for image, detections in my_data_source:\n",
    "        # - image is a BGR color image\n",
    "        # - detections is an Nx4 matrix of bounding boxes in\n",
    "        #   format (x, y, w, h) where (x, y) is the top-left corner\n",
    "        #   and (w, h) is the extent\n",
    "        # - features is an Nx128 matrix of corresponding appearance descriptors\n",
    "        features = encoder(image, detections)\n",
    "        \n",
    "        # Generate a list of detections (we simply set the confidence\n",
    "        # score to 1.0 here).\n",
    "        detections = [\n",
    "            Detection(bbox, 1.0, feature) for bbox, feature in\n",
    "            zip(detections, features)]\n",
    "\n",
    "        # Call the tracker\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "\n",
    "        # Go on and visualize the results, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "\n",
    "# Mask-R-CNN\n",
    "MASKRCNN_DIR = 'maskrcnn'\n",
    "MODEL_DIR = os.path.join(\"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(\"mask_rcnn_coco.h5\")\n",
    "\n",
    "VIDEO_DIR = 'videos'\n",
    "VIDEO_FILE = 'transition.mp4'\n",
    "video = os.path.join(VIDEO_DIR, VIDEO_FILE)\n",
    "\n",
    "def to_mot_format(frame_idx, coord):\n",
    "    \"\"\"\n",
    "    Input coordinates: \n",
    "    (y1, x1, y2, x2)\n",
    "    \n",
    "    Output coordinates: \n",
    "    (frame, id, bb_left, bb_top, bb_width, bb_height, -1, -1, -1, -1)\n",
    "    \"\"\"\n",
    "    padding = np.array([-1, -1, -1, -1])\n",
    "    \n",
    "    coord = np.insert(coord, 0, frame_idx)\n",
    "    coord = np.insert(coord, 1, -1)\n",
    "    coord = np.append(coord, padding)\n",
    "    \n",
    "    width = coord[5] - coord[3]\n",
    "    height = coord[4] - coord[2]\n",
    "    \n",
    "    coord[4] = width\n",
    "    coord[5] = height\n",
    "\n",
    "    # Rearrange coordinates\n",
    "    coord = coord[[0, 1, 3, 2, 4, 5, 6, 7, 8, 9]]\n",
    "    \n",
    "    return coord\n",
    "\n",
    "def get_detections_frame(image, frame_idx):\n",
    "    class InferenceConfig(coco.CocoConfig):\n",
    "        # Set batch size to 1 since we'll be running inference on\n",
    "        # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = 1\n",
    "        \n",
    "    config = InferenceConfig()\n",
    "    \n",
    "    # Create model object in inference mode.\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "    # Load weights trained on MS-COCO\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "    \n",
    "    results = model.detect([image], verbose=0)\n",
    "    rois = results[0]['rois']\n",
    "    \n",
    "    detections = np.zeros([len(rois), 10])\n",
    "    \n",
    "    for idx, coord in enumerate(rois):\n",
    "        detections[idx] = to_mot_format(frame_idx, coord)\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def get_detections_video(video):\n",
    "    \"\"\"\n",
    "    Get ROI detections from video using Mask-R-CNN and save in \n",
    "    MOTChallenge format\n",
    "    \"\"\"    \n",
    "    camera = cv2.VideoCapture(video)\n",
    "    num_frames = int(camera.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    success,image = camera.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "\n",
    "    \n",
    "    while success:\n",
    "        success,image = camera.read()\n",
    "        print(\"Processing image {}\".format(count))\n",
    "        detection = get_detections_frame(image, count)\n",
    "        print(detection)\n",
    "        if count == 0:\n",
    "            detections = detection\n",
    "        else:\n",
    "            detections = np.concatenate((detections, detection))\n",
    "        \n",
    "        if count == 3:\n",
    "            break\n",
    "            \n",
    "        count += 1\n",
    "        \n",
    "    return detections\n",
    "    \n",
    "detections = get_detections_video(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort.deep_sort import generate_detections\n",
    "from deep_sort.detection import Detection\n",
    "\n",
    "DEEP_SORT_DIR = 'deep_sort'\n",
    "DETECTION_DIR = 'detections'\n",
    "\n",
    "VIDEO_DIR = 'videos'\n",
    "VIDEO_FILE = 'transition.mp4'\n",
    "\n",
    "CHECKPOINT_PATH = os.path.join(DEEP_SORT_DIR, 'checkpoint', 'mars-small128.ckpt-68577')\n",
    "\n",
    "encoder = generate_detections.create_box_encoder(CHECKPOINT_PATH)\n",
    "video = os.path.join(VIDEO_DIR, VIDEO_FILE)\n",
    "name_out = 'detections_file'\n",
    "\n",
    "def generate_detections_features(encoder, video, name_out, detection):\n",
    "\n",
    "    \"\"\"Generate detections with features. Modification with video\"\"\"\n",
    "    detections_in = np.loadtxt(detection_file, delimiter=',')\n",
    "    detections_in = detection\n",
    "    detections_out = []\n",
    "\n",
    "    frame_indices = detections_in[:, 0].astype(np.int)\n",
    "    min_frame_idx = frame_indices.astype(np.int).min()\n",
    "    max_frame_idx = frame_indices.astype(np.int).max()\n",
    "\n",
    "    camera = cv2.VideoCapture(video)\n",
    "\n",
    "    for frame_idx in range(min_frame_idx, max_frame_idx + 1):\n",
    "        print(\"Frame %05d/%05d\" % (frame_idx, max_frame_idx))\n",
    "        mask = frame_indices == frame_idx\n",
    "        rows = detections_in[mask]\n",
    "\n",
    "        if frame_idx not in frame_indices:\n",
    "            print(\"WARNING could not find image for frame %d\" % frame_idx)\n",
    "            continue\n",
    "        camera.set(cv2.CAP_PROP_POS_FRAMES, frame_idx-1);\n",
    "        (grabbed, bgr_image) = camera.read()\n",
    "        # bgr_image = cv2.imread(image_filenames[frame_idx], cv2.IMREAD_COLOR)\n",
    "        rows[:, 4:6] -= rows[:, 2:4]  # convert to [x1,y1,x2,y2] to [x1,y1,w,h]\n",
    "        features = encoder(bgr_image, rows[:, 2:6].copy())\n",
    "        detections_out += [np.r_[(row, feature)] for row, feature\n",
    "                           in zip(rows, features)]\n",
    "\n",
    "    # output_filename = os.path.join(output_dir, \"%s.npy\" % sequence)\n",
    "    np.save(name_out, np.asarray(detections_out), allow_pickle=False)\n",
    "\n",
    "\n",
    "def tracking(detections_file):\n",
    "    \"\"\" Track objects\"\"\"\n",
    "    frame_idx = 0;\n",
    "    min_frame_idx = int(detections_file[:, 0].min())\n",
    "    max_frame_idx = int(detections_file[:, 0].max())\n",
    "    min_confidence = 0.95\n",
    "    min_detection_height = 0\n",
    "    nms_max_overlap = 0.3\n",
    "    \n",
    "    if (display):\n",
    "        plt.ion()\n",
    "        fig = plt.figure()\n",
    "\n",
    "    while True:\n",
    "        (grabbed, frame) = camera.read()\n",
    "        frame_idx += 1;\n",
    "        print(\"Processing frame %05d\" % frame_idx)\n",
    "\n",
    "        # Load image and generate detections.\n",
    "        detections = create_detections(detections_file, frame_idx-1, min_detection_height)\n",
    "        detections = [d for d in detections if d.confidence >= min_confidence]\n",
    "\n",
    "        # Run non-maxima suppression.\n",
    "        boxes = np.array([d.tlwh for d in detections])\n",
    "        scores = np.array([d.confidence for d in detections])\n",
    "        indices = preprocessing.non_max_suppression(boxes, nms_max_overlap, scores)\n",
    "        detections = [detections[i] for i in indices]\n",
    "\n",
    "        # Update tracker.\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "\n",
    "        # Update visualization.\n",
    "        if display:\n",
    "            ax1 = fig.add_subplot(111, aspect='equal')\n",
    "            # fn = 'mot_benchmark/%s/%s/img1/%06d.jpg'%(phase,seq,frame)\n",
    "            ax1.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            plt.title(' Tracked Targets')\n",
    "\n",
    "        # Store results.\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "            bbox = track.to_tlwh()\n",
    "            results.append([\n",
    "                frame_idx, track.track_id, bbox[0], bbox[1], bbox[2], bbox[3]])\n",
    "\n",
    "         \n",
    "            if (display):\n",
    "                ax1.add_patch(patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], fill=False, lw=3,ec=colours[track.track_id % 32, :]))\n",
    "                ax1.set_adjustable('box-forced')\n",
    "                plt.text(bbox[0], bbox[1], str(track.track_id))\n",
    "\n",
    "        if(display):\n",
    "            fig.canvas.flush_events()\n",
    "            plt.draw()\n",
    "            ax1.cla()\n",
    "\n",
    "        if grabbed == False:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
