{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "\"As I explained before: you have to do detection with py-faster-rcnn and then a tracking using deep sort.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use mask-r-cnn to get detections in ROI format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"nba-images\")\n",
    "\n",
    "########################################\n",
    "\n",
    "\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "\n",
    "\"\"\"Create Model and Load Trained Weights\"\"\"\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "\n",
    "# class_names = ['person']\n",
    "\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "\n",
    "# Load a random image from the images folder\n",
    "file_names = next(os.walk(IMAGE_DIR))[2]\n",
    "image = skimage.io.imread(os.path.join(IMAGE_DIR, random.choice(file_names)))\n",
    "\n",
    "# Run detection\n",
    "results = model.detect([image], verbose=1)\n",
    "\n",
    "# Visualize results\n",
    "r = results[0]\n",
    "print(r['rois'].shape)\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import skvideo.io\n",
    "import numpy as np\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "\n",
    "# Mask-R-CNN\n",
    "MASKRCNN_DIR = 'maskrcnn'\n",
    "MODEL_DIR = os.path.join(\"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(\"mask_rcnn_coco.h5\")\n",
    "\n",
    "VIDEO_DIR = 'videos'\n",
    "VIDEO_FILE = 'transition.mp4'\n",
    "video = os.path.join(VIDEO_DIR, VIDEO_FILE)\n",
    "\n",
    "# Save video frames\n",
    "FRAMES_DIR = 'frames'\n",
    "\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "def get_detections_frame(model, image, frame_idx):\n",
    "    results = model.detect([image], verbose=0)\n",
    "    rois = results[0]['rois']\n",
    "    \n",
    "    detections = np.zeros([len(rois), 10])\n",
    "    \n",
    "    for idx, coord in enumerate(rois):\n",
    "        detections[idx] = to_mot_format(frame_idx, coord)\n",
    "    \n",
    "    return detections\n",
    "\n",
    "\n",
    "def write_to_csv(csv_file, row_titles = None, new_row = None, new_file = 'no'):\n",
    "    if new_file == 'yes':\n",
    "        rwa = 'w'\n",
    "    else:\n",
    "        rwa = 'a'\n",
    "    with open(csv_file, rwa) as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',',quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        if row_titles:\n",
    "            writer.writerow(row_titles)\n",
    "        if new_row:\n",
    "            writer.writerow(new_row)\n",
    "    csvfile.close()\n",
    "    \n",
    "def to_mot_format(frame_idx, coord):\n",
    "    \"\"\"\n",
    "    Input coordinates: \n",
    "    (y1, x1, y2, x2)\n",
    "    \n",
    "    Output coordinates: \n",
    "    (frame, id, bb_left, bb_top, bb_width, bb_height, -1, -1, -1, -1)\n",
    "    \"\"\"\n",
    "    padding = np.array([-1, -1, -1, -1])\n",
    "    \n",
    "    coord = np.insert(coord, 0, frame_idx)\n",
    "    coord = np.insert(coord, 1, -1)\n",
    "    coord = np.append(coord, padding)\n",
    "    \n",
    "    width = coord[5] - coord[3]\n",
    "    height = coord[4] - coord[2]\n",
    "    \n",
    "    coord[4] = width\n",
    "    coord[5] = height\n",
    "\n",
    "    # Rearrange coordinates\n",
    "    coord = coord[[0, 1, 3, 2, 4, 5, 6, 7, 8, 9]]\n",
    "    \n",
    "    return coord\n",
    "\n",
    "def get_detections_video(video):\n",
    "    \"\"\"\n",
    "    Get ROI detections from video using Mask-R-CNN and save in \n",
    "    MOTChallenge format\n",
    "    \"\"\"    \n",
    "    videodata = skvideo.io.vread(video)\n",
    "    num_frames = len(videodata)\n",
    "    det_file = open('detections.txt', 'ab')\n",
    "    \n",
    "    for idx, frame in enumerate(videodata):\n",
    "        try:\n",
    "            print(\"PROCESSING IMAGE {} / {}\".format(idx, num_frames))\n",
    "            detection = get_detections_frame(model, frame, idx)\n",
    "            np.savetxt(det_file, detection, delimiter=',', fmt='%1.2f')\n",
    "            print(\"DONE\")\n",
    "        except:\n",
    "            print(\"FRAME {} NOT PROCESSED\".format(idx))\n",
    "\n",
    "        det_file.flush()\n",
    "    \n",
    "    det_file.close()\n",
    "    \n",
    "    print(\"FINISHED!\")\n",
    "\n",
    "get_detections_video(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate detection features using Deep SORT and append to detections file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import generate_detections\n",
    "import Detection\n",
    "import numpy as np\n",
    "import skvideo.io\n",
    "\n",
    "DETECTION_DIR = 'detections'\n",
    "\n",
    "VIDEO_DIR = 'videos'\n",
    "VIDEO_FILE = 'transition.mp4'\n",
    "\n",
    "CHECKPOINT_PATH = os.path.join('resources', 'networks', 'mars-small128.pb')\n",
    "\n",
    "encoder = generate_detections.create_box_encoder(CHECKPOINT_PATH)\n",
    "video = os.path.join(VIDEO_DIR, VIDEO_FILE)\n",
    "name_out = 'generated_detections'\n",
    "detection_file = 'detections.txt'\n",
    "\n",
    "def generate_detections_features(encoder, video, name_out, detection_file):\n",
    "\n",
    "    \"\"\"Generate detections with features. Modification with video\"\"\"\n",
    "    detections_in = np.loadtxt(detection_file, delimiter=',')\n",
    "    detections_out = []\n",
    "\n",
    "    frame_indices = detections_in[:, 0].astype(np.int)\n",
    "    min_frame_idx = frame_indices.astype(np.int).min()\n",
    "    max_frame_idx = frame_indices.astype(np.int).max()\n",
    "\n",
    "    videodata = skvideo.io.vread(video)\n",
    "    \n",
    "\n",
    "    for frame_idx in range(min_frame_idx, max_frame_idx + 1):\n",
    "        print(\"Frame %05d/%05d\" % (frame_idx, max_frame_idx))\n",
    "        mask = frame_indices == frame_idx\n",
    "        rows = detections_in[mask]\n",
    "\n",
    "        if frame_idx not in frame_indices:\n",
    "            print(\"WARNING could not find image for frame %d\" % frame_idx)\n",
    "            continue\n",
    "            \n",
    "#         camera.set(cv2.CAP_PROP_POS_FRAMES, frame_idx-1);\n",
    "#         (grabbed, bgr_image) = camera.read()\n",
    "#         bgr_image = cv2.imread(image_filenames[frame_idx], cv2.IMREAD_COLOR)  \n",
    "\n",
    "        bgr_image = videodata[frame_idx]\n",
    "\n",
    "        features = encoder(bgr_image, rows[:, 2:6].copy())\n",
    "        detections_out += [np.r_[(row, feature)] for row, feature\n",
    "                           in zip(rows, features)]\n",
    "\n",
    "    # output_filename = os.path.join(output_dir, \"%s.npy\" % sequence)\n",
    "    np.save(name_out, np.asarray(detections_out), allow_pickle=False)\n",
    "    \n",
    "generate_detections_features(encoder, video, name_out, detection_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Deep SORT tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.deep_sort_app import create_detections\n",
    "from deep_sort.application_util import preprocessing\n",
    "from deep_sort.tracker import Tracker\n",
    "\n",
    "\n",
    "def tracking(detections_file):\n",
    "    \"\"\" Track objects\"\"\"\n",
    "    detections_file = np.load(detections_file)\n",
    "    min_frame_idx = int(detections_file[:, 0].min())\n",
    "    max_frame_idx = int(detections_file[:, 0].max())\n",
    "    min_confidence = -1\n",
    "    min_detection_height = 0\n",
    "    nms_max_overlap = 0.3\n",
    "    \n",
    "    videodata = skvideo.io.vread(video)\n",
    "    \n",
    "    if (display):\n",
    "        plt.ion()\n",
    "        fig = plt.figure()\n",
    "\n",
    "    for frame_idx in range(min_frame_idx, max_frame_idx + 1):\n",
    "        \n",
    "        frame = videodata[frame_idx]\n",
    "        \n",
    "        print(\"Processing frame {}\".format(frame_idx + 1))\n",
    "\n",
    "        # Load image and generate detections.\n",
    "        detections = create_detections(detections_file, frame_idx, min_detection_height)\n",
    "        detections = [d for d in detections if d.confidence >= min_confidence]\n",
    "\n",
    "        # Run non-maxima suppression.\n",
    "        boxes = np.array([d.tlwh for d in detections])\n",
    "        scores = np.array([d.confidence for d in detections])\n",
    "        indices = preprocessing.non_max_suppression(boxes, nms_max_overlap, scores)\n",
    "        detections = [detections[i] for i in indices]\n",
    "\n",
    "        # Update tracker.\n",
    "        max_cosine_distance = 0.05\n",
    "        nn_budget = 1\n",
    "        \n",
    "        metric = nn_matching.NearestNeighborDistanceMetric(\n",
    "            \"cosine\", max_cosine_distance, nn_budget)\n",
    "        \n",
    "        tracker = Tracker(metric)\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "\n",
    "        # Update visualization.\n",
    "        if display:\n",
    "            ax1 = fig.add_subplot(111, aspect='equal')\n",
    "            # fn = 'mot_benchmark/%s/%s/img1/%06d.jpg'%(phase,seq,frame)\n",
    "            ax1.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            plt.title(' Tracked Targets')\n",
    "\n",
    "        # Store results.\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "            bbox = track.to_tlwh()\n",
    "            results.append([\n",
    "                frame_idx+1, track.track_id, bbox[0], bbox[1], bbox[2], bbox[3]])\n",
    "\n",
    "         \n",
    "            if (display):\n",
    "                ax1.add_patch(patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], fill=False, lw=3,ec=colours[track.track_id % 32, :]))\n",
    "                ax1.set_adjustable('box-forced')\n",
    "                plt.text(bbox[0], bbox[1], str(track.track_id))\n",
    "\n",
    "        if(display):\n",
    "            fig.canvas.flush_events()\n",
    "            plt.draw()\n",
    "            ax1.cla()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking('generated_detections.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
