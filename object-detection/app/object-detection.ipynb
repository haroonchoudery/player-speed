{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "\"As I explained before: you have to do detection with py-faster-rcnn and then a tracking using deep sort.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use mask-r-cnn to get detections in ROI format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"nba-images\")\n",
    "\n",
    "########################################\n",
    "\n",
    "\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "\n",
    "\"\"\"Create Model and Load Trained Weights\"\"\"\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "# COCO Class names\n",
    "# Index of the class in the list is its ID. For example, to get ID of\n",
    "# the teddy bear class, use: class_names.index('teddy bear')\n",
    "\n",
    "# class_names = ['person']\n",
    "\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "\n",
    "# Load a random image from the images folder\n",
    "file_names = next(os.walk(IMAGE_DIR))[2]\n",
    "image = skimage.io.imread(os.path.join(IMAGE_DIR, random.choice(file_names)))\n",
    "\n",
    "# Run detection\n",
    "results = model.detect([image], verbose=1)\n",
    "\n",
    "# Visualize results\n",
    "r = results[0]\n",
    "print(r['rois'].shape)\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import generate_detections\n",
    "from deep_sort.detection import Detection\n",
    "\n",
    "DEEP_SORT_DIR = 'deep_sort'\n",
    "MASKRCNN_DIR = 'maskrcnn'\n",
    "TEST_IMG = 'maskrcnn/nba-images/frame_000009.jpg'\n",
    "\n",
    "CHECKPOINT_PATH = os.path.join(DEEP_SORT_DIR, \"checkpoint\", \"mars-small128.ckpt-68577\")\n",
    "\n",
    "def main():\n",
    "    # Start up your application, then generate the encoder function.\n",
    "    encoder = generate_detections.create_box_encoder(CHECKPOINT_PATH)\n",
    "\n",
    "    # Now, enter the application main loop. Should be something like this:\n",
    "    for image, detections in my_data_source:\n",
    "        # - image is a BGR color image\n",
    "        # - detections is an Nx4 matrix of bounding boxes in\n",
    "        #   format (x, y, w, h) where (x, y) is the top-left corner\n",
    "        #   and (w, h) is the extent\n",
    "        # - features is an Nx128 matrix of corresponding appearance descriptors\n",
    "        features = encoder(image, detections)\n",
    "        \n",
    "        # Generate a list of detections (we simply set the confidence\n",
    "        # score to 1.0 here).\n",
    "        detections = [\n",
    "            Detection(bbox, 1.0, feature) for bbox, feature in\n",
    "            zip(detections, features)]\n",
    "\n",
    "        # Call the tracker\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "\n",
    "        # Go on and visualize the results, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import generate_detections\n",
    "from deep_sort.detection import Detection\n",
    "\n",
    "DEEP_SORT_DIR = 'deep_sort'\n",
    "MASKRCNN_DIR = 'maskrcnn'\n",
    "\n",
    "CHECKPOINT_PATH = os.path.join(DEEP_SORT_DIR, \"checkpoint\", \"mars-small128.ckpt-68577\")\n",
    "\n",
    "def main():\n",
    "    # Start up your application, then generate the encoder function.\n",
    "    encoder = generate_detections.create_box_encoder(CHECKPOINT_PATH)\n",
    "\n",
    "    # Now, enter the application main loop. Should be something like this:\n",
    "    for image, detections in my_data_source:\n",
    "        # - image is a BGR color image\n",
    "        # - detections is an Nx4 matrix of bounding boxes in\n",
    "        #   format (x, y, w, h) where (x, y) is the top-left corner\n",
    "        #   and (w, h) is the extent\n",
    "        # - features is an Nx128 matrix of corresponding appearance descriptors\n",
    "        features = encoder(image, detections)\n",
    "        \n",
    "        # Generate a list of detections (we simply set the confidence\n",
    "        # score to 1.0 here).\n",
    "        detections = [\n",
    "            Detection(bbox, 1.0, feature) for bbox, feature in\n",
    "            zip(detections, features)]\n",
    "\n",
    "        # Call the tracker\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "\n",
    "        # Go on and visualize the results, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 0\n",
      "[[  0.  -1. 209. 296.  98. 148.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 478. 258.  95. 179.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1.   1. 368. 125. 200.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 574. 231.  61. 133.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 157. 212.  48.  76.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 214. 186.  57. 115.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 433. 181.  38.  84.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1.   1. 190.  48. 119.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 386. 182.  35.  87.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 970. 259.  44. 169.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 462. 248.  41. 178.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 730. 269.  89. 150.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 358. 187.  30.  81.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1.  45. 181.  52.  59.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 558. 171.  49.  73.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 631. 202.  51.  57.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 172. 167.  41.  65.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 491. 171.  32.  84.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 257. 188.  47.  95.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 124. 128.  39.  68.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 126. 209.  31.  59.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 469. 169.  37.  87.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 140.  90.  41.  59.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 338. 154.  25.  50.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 606. 178.  34.  67.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 763. 168.  27.  48.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 504. 283.  39.  48.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 765. 186.  46.  60.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 289. 129.  28.  44.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 162. 168.  27.  53.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 420. 152.  27.  38.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 524. 197.  39.  62.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 309. 158.  26.  41.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 395. 151.  25.  36.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 361. 138.  23.  44.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 542.  63.  35.  82.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 839. 203.  40.  61.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 814. 214.  34.  41.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 834. 542.  34.  32.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 409. 187.  30.  73.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 694. 190.  33.  39.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 317.  30.  41.  73.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1.  19.   1.  35.  65.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 717. 228.  56.  59.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 626. 173.  30.  62.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 378. 176.  21.  22.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1.  63. 142.  51.  53.  -1.  -1.  -1.  -1.]\n",
      " [  0.  -1. 523. 121.  27.  54.  -1.  -1.  -1.  -1.]]\n",
      "Processing image 1\n",
      "[[  1.  -1. 199. 291. 106. 157.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 738. 262.  92. 157.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 574. 228.  65. 136.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 215. 183.  41. 111.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 489. 251.  60. 138.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 388. 184.  34.  83.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 969. 261.  46. 164.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 461. 254.  42. 166.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 361. 185.  30.  81.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 155. 211.  48.  75.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 433. 181.  38.  83.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1.   1. 345. 112. 226.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1.   0. 189.  46. 118.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 633. 202.  50.  56.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 559. 167.  49.  74.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 175. 165.  40.  61.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1.  48. 181.  51.  55.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 494. 169.  29.  84.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 469. 167.  27.  89.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 289. 128.  29.  47.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 947. 543.  31.  31.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 620. 169.  40.  74.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 126. 128.  37.  66.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 394. 150.  27.  35.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 407. 188.  32.  71.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 336. 155.  26.  39.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 167. 155.  27.  54.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 229. 146.  26.  45.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 764. 190.  53.  74.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 306. 150.  32.  56.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 145.  91.  36.  70.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 542.  62.  35.  87.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 715. 231.  58.  58.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 524. 194.  40.  65.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 361. 138.  24.  43.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 763. 169.  26.  45.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 501. 280.  36.  44.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 348. 192.  26.  74.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 238. 190.  38.  97.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 131. 209.  26.  46.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 423. 148.  26.  43.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 816. 191.  37.  64.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 318.  29.  42.  75.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 836. 196.  41.  73.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 268. 187.  40.  97.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1.  36. 111.  60.  64.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 523. 120.  28.  53.  -1.  -1.  -1.  -1.]\n",
      " [  1.  -1. 279. 121.  21.  41.  -1.  -1.  -1.  -1.]]\n",
      "Processing image 2\n",
      "[[  2.  -1. 199. 292. 103. 162.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 740. 264.  90. 151.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 212. 186.  45. 108.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 575. 224.  59. 125.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1.  47. 178.  57.  59.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 387. 182.  36.  83.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 484. 253.  58. 142.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 967. 258.  48. 165.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 435. 181.  37.  82.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 155. 208.  48.  77.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 361. 184.  31.  81.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 461. 253.  41. 166.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 633. 201.  50.  59.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 560. 166.  48.  73.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 494. 167.  29.  86.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 469. 167.  28.  86.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 180. 167.  34.  56.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 290. 126.  30.  48.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 620. 169.  40.  72.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 269. 179.  41. 104.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1.   0. 189.  46. 118.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1.   0. 406.  98. 163.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 765. 559.  30.  17.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 813. 190.  39.  66.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 674. 208.  45.  70.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 393. 151.  27.  34.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 766. 182.  44.  64.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 126. 128.  37.  67.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 145.  91.  37.  66.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 724. 227.  55.  58.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 307. 144.  32.  63.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 540.  60.  36.  89.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 524. 187.  37.  69.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 341. 152.  24.  48.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 763. 169.  27.  42.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 319.  28.  42.  69.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 837. 194.  39.  75.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 410. 184.  34.  77.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 361. 138.  25.  43.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 280. 120.  23.  45.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 552. 171.  23.  46.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 344. 182.  30.  84.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 668. 157.  39.  63.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 326. 189.  24.  65.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1.   0. 373.  36. 119.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 168. 144.  29.  57.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 428. 144.  32.  41.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 183. 209.  37.  79.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 693. 189.  33.  41.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 574.  69.  38.  76.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 239. 182.  41. 106.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 244. 114.  25.  45.  -1.  -1.  -1.  -1.]\n",
      " [  2.  -1. 606. 165.  31.  79.  -1.  -1.  -1.  -1.]]\n",
      "Processing image 3\n",
      "[[  3.  -1. 466. 251.  79. 172.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 740. 265.  93. 152.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 203. 183.  72. 125.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 575. 221.  58. 138.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 389. 183.  35.  82.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 435. 181.  37.  82.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 198. 300. 105. 138.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 968. 259.  46. 159.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1.  47. 177.  60.  58.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 629. 199.  55.  66.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 562. 164.  46.  76.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 495. 169.  27.  82.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 362. 184.  31.  80.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 469. 172.  27.  80.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1.   1. 392.  85. 179.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 192. 380.  48.  74.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 156. 204.  48.  82.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 943. 540.  34.  33.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 270. 179.  53.  97.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 621. 169.  39.  72.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 178. 162.  39.  67.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 764. 190.  53.  56.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 293. 123.  25.  50.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 765. 558.  30.  18.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 144.  88.  41.  81.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 319.  20.  44.  70.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 393. 151.  28.  34.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 235. 155.  37.  74.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 526. 193.  36.  63.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 812. 185.  41.  72.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 340. 153.  23.  45.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 762. 172.  25.  44.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 329. 187.  22.  58.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 410. 184.  35.  77.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 717. 229.  58.  56.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 675. 205.  43.  73.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 311. 153.  28.  43.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 237. 210.  29.  47.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 837. 194.  40.  92.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1.   3. 123.  42.  66.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 266. 140.  31.  84.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 338. 175.  33.  89.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 425. 146.  23.  39.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 606. 164.  29.  79.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 134. 193.  38.  94.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 485. 275.  43.  47.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 670. 154.  37.  82.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 736. 189.  36.  38.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 522. 178.  20.  65.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -1. 521. 118.  30.  54.  -1.  -1.  -1.  -1.]]\n",
      "Processing image 4\n",
      "[[  4.  -1. 465. 247.  76. 179.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 752. 262.  93. 155.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 575. 218.  61. 141.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 968. 265.  44. 154.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 206. 186.  64. 122.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 389. 183.  36.  81.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1.  54. 176.  53.  58.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1.   0. 408.  69. 164.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 435. 182.  37.  81.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 157. 199.  48.  87.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 364. 183.  29.  80.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 470. 171.  28.  80.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 633. 198.  47.  59.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 495. 171.  28.  79.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 281. 180.  55.  73.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 568. 168.  40.  69.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 190. 299.  64. 101.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 623. 170.  37.  70.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 528. 197.  36.  60.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 943. 538.  33.  37.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 145.  86.  41.  76.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 319.  14.  45.  75.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 761. 192.  52.  55.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 312. 147.  30.  60.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 710. 227.  46.  60.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 482. 274.  41.  46.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 338. 161.  33.  94.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 411. 184.  36.  76.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 395. 149.  27.  36.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 293. 123.  25.  49.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 134. 199.  34.  86.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 265. 141.  32.  74.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1.   0. 191.  46. 112.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 849. 521.  90.  53.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 767. 226.  54.  56.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 552. 169.  22.  43.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 669. 199.  47.  78.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 837. 201.  42. 108.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 235. 209.  32.  51.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 822. 534.  37.  42.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 740. 185.  33.  43.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 608. 173.  26.  65.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 235. 148.  30.  79.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 461. 260.  31. 156.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 169. 143.  34.  71.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 808. 196.  41.  66.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 366. 140.  23.  41.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 523. 177.  19.  60.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 761. 172.  27.  44.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 213. 113.  24.  53.  -1.  -1.  -1.  -1.]\n",
      " [  4.  -1. 436. 141.  30.  40.  -1.  -1.  -1.  -1.]]\n",
      "Processing image 5\n",
      "[[  5.  -1. 462. 243.  69. 183.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 754. 259.  83. 156.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 573. 213.  62. 146.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 966. 259.  44. 159.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 190. 306.  84. 139.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 365. 181.  30.  82.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 391. 182.  38.  82.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 438. 181.  35.  80.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 281. 179.  58.  71.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1.   0. 383.  54. 188.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1.  54. 176.  50.  58.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 161. 201.  42.  83.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 496. 170.  28.  82.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 196. 170.  56. 135.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1.   0. 187.  43. 116.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 630. 201.  50.  58.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 471. 170.  26.  80.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 566. 166.  41.  68.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 943. 535.  32.  41.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 147.  85.  39.  84.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 616. 165.  41.  75.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 138. 196.  35.  89.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 708. 226.  41.  61.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 344. 179.  35.  83.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 836. 521.  96.  50.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 818. 532.  41.  44.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 770. 554.  24.  22.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 532. 199.  28.  55.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 294. 124.  27.  46.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 736. 180.  36.  48.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 213. 115.  26.  49.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 668. 198.  45.  77.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 764. 190.  52.  56.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 731. 227.  43.  55.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 415. 187.  26.  66.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 770. 227.  54.  60.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 829. 191.  53. 119.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 316. 130.  37.  67.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 338. 158.  30.  43.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 122.  65.  27.  70.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 270. 148.  31.  67.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 235. 148.  39.  86.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 553. 168.  21.  43.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 367. 139.  22.  41.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 670. 163.  36.  72.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 522. 182.  21.  63.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 396. 149.  26.  36.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1.  86. 191.  50.  46.  -1.  -1.  -1.  -1.]\n",
      " [  5.  -1. 761. 170.  27.  46.  -1.  -1.  -1.  -1.]]\n",
      "Processing image 6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "\n",
    "# Mask-R-CNN\n",
    "MASKRCNN_DIR = 'maskrcnn'\n",
    "MODEL_DIR = os.path.join(\"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(\"mask_rcnn_coco.h5\")\n",
    "\n",
    "VIDEO_DIR = 'videos'\n",
    "VIDEO_FILE = 'transition.mp4'\n",
    "video = os.path.join(VIDEO_DIR, VIDEO_FILE)\n",
    "\n",
    "def to_mot_format(frame_idx, coord):\n",
    "    \"\"\"\n",
    "    Input coordinates: \n",
    "    (y1, x1, y2, x2)\n",
    "    \n",
    "    Output coordinates: \n",
    "    (frame, id, bb_left, bb_top, bb_width, bb_height, -1, -1, -1, -1)\n",
    "    \"\"\"\n",
    "    padding = np.array([-1, -1, -1, -1])\n",
    "    \n",
    "    coord = np.insert(coord, 0, frame_idx)\n",
    "    coord = np.insert(coord, 1, -1)\n",
    "    coord = np.append(coord, padding)\n",
    "    \n",
    "    width = coord[5] - coord[3]\n",
    "    height = coord[4] - coord[2]\n",
    "    \n",
    "    coord[4] = width\n",
    "    coord[5] = height\n",
    "\n",
    "    # Rearrange coordinates\n",
    "    coord = coord[[0, 1, 3, 2, 4, 5, 6, 7, 8, 9]]\n",
    "    \n",
    "    return coord\n",
    "\n",
    "def get_detections_frame(image, frame_idx):\n",
    "    class InferenceConfig(coco.CocoConfig):\n",
    "        # Set batch size to 1 since we'll be running inference on\n",
    "        # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = 1\n",
    "        \n",
    "    config = InferenceConfig()\n",
    "    \n",
    "    # Create model object in inference mode.\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "    # Load weights trained on MS-COCO\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "    \n",
    "    results = model.detect([image], verbose=0)\n",
    "    rois = results[0]['rois']\n",
    "    \n",
    "    detections = np.zeros([len(rois), 10])\n",
    "    \n",
    "    for idx, coord in enumerate(rois):\n",
    "        detections[idx] = to_mot_format(frame_idx, coord)\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def get_detections_video(video):\n",
    "    \"\"\"\n",
    "    Get ROI detections from video using Mask-R-CNN and save in \n",
    "    MOTChallenge format\n",
    "    \"\"\"    \n",
    "    camera = cv2.VideoCapture(video)\n",
    "    num_frames = int(camera.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    success,image = camera.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "\n",
    "    \n",
    "    while success:\n",
    "        success,image = camera.read()\n",
    "        print(\"Processing image {}\".format(count))\n",
    "        detection = get_detections_frame(image, count)\n",
    "        print(detection)\n",
    "        if count == 0:\n",
    "            detections = detection\n",
    "        else:\n",
    "            detections = np.concatenate((detections, detection))\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    return detections\n",
    "    \n",
    "detections = get_detections_video(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort.deep_sort import generate_detections\n",
    "from deep_sort.detection import Detection\n",
    "\n",
    "DEEP_SORT_DIR = 'deep_sort'\n",
    "DETECTION_DIR = 'detections'\n",
    "\n",
    "VIDEO_DIR = 'videos'\n",
    "VIDEO_FILE = 'transition.mp4'\n",
    "\n",
    "CHECKPOINT_PATH = os.path.join(DEEP_SORT_DIR, 'checkpoint', 'mars-small128.ckpt-68577')\n",
    "\n",
    "encoder = generate_detections.create_box_encoder(CHECKPOINT_PATH)\n",
    "video = os.path.join(VIDEO_DIR, VIDEO_FILE)\n",
    "name_out = 'detections_file'\n",
    "\n",
    "def generate_detections_features(encoder, video, name_out, detection):\n",
    "\n",
    "    \"\"\"Generate detections with features. Modification with video\"\"\"\n",
    "    detections_in = np.loadtxt(detection_file, delimiter=',')\n",
    "    detections_in = detection\n",
    "    detections_out = []\n",
    "\n",
    "    frame_indices = detections_in[:, 0].astype(np.int)\n",
    "    min_frame_idx = frame_indices.astype(np.int).min()\n",
    "    max_frame_idx = frame_indices.astype(np.int).max()\n",
    "\n",
    "    camera = cv2.VideoCapture(video)\n",
    "\n",
    "    for frame_idx in range(min_frame_idx, max_frame_idx + 1):\n",
    "        print(\"Frame %05d/%05d\" % (frame_idx, max_frame_idx))\n",
    "        mask = frame_indices == frame_idx\n",
    "        rows = detections_in[mask]\n",
    "\n",
    "        if frame_idx not in frame_indices:\n",
    "            print(\"WARNING could not find image for frame %d\" % frame_idx)\n",
    "            continue\n",
    "        camera.set(cv2.CAP_PROP_POS_FRAMES, frame_idx-1);\n",
    "        (grabbed, bgr_image) = camera.read()\n",
    "        # bgr_image = cv2.imread(image_filenames[frame_idx], cv2.IMREAD_COLOR)\n",
    "        rows[:, 4:6] -= rows[:, 2:4]  # convert to [x1,y1,x2,y2] to [x1,y1,w,h]\n",
    "        features = encoder(bgr_image, rows[:, 2:6].copy())\n",
    "        detections_out += [np.r_[(row, feature)] for row, feature\n",
    "                           in zip(rows, features)]\n",
    "\n",
    "    # output_filename = os.path.join(output_dir, \"%s.npy\" % sequence)\n",
    "    np.save(name_out, np.asarray(detections_out), allow_pickle=False)\n",
    "\n",
    "\n",
    "def tracking(detections_file):\n",
    "    \"\"\" Track objects\"\"\"\n",
    "    frame_idx = 0;\n",
    "    min_frame_idx = int(detections_file[:, 0].min())\n",
    "    max_frame_idx = int(detections_file[:, 0].max())\n",
    "    min_confidence = 0.95\n",
    "    min_detection_height = 0\n",
    "    nms_max_overlap = 0.3\n",
    "    \n",
    "    if (display):\n",
    "        plt.ion()\n",
    "        fig = plt.figure()\n",
    "\n",
    "    while True:\n",
    "        (grabbed, frame) = camera.read()\n",
    "        frame_idx += 1;\n",
    "        print(\"Processing frame %05d\" % frame_idx)\n",
    "\n",
    "        # Load image and generate detections.\n",
    "        detections = create_detections(detections_file, frame_idx-1, min_detection_height)\n",
    "        detections = [d for d in detections if d.confidence >= min_confidence]\n",
    "\n",
    "        # Run non-maxima suppression.\n",
    "        boxes = np.array([d.tlwh for d in detections])\n",
    "        scores = np.array([d.confidence for d in detections])\n",
    "        indices = preprocessing.non_max_suppression(boxes, nms_max_overlap, scores)\n",
    "        detections = [detections[i] for i in indices]\n",
    "\n",
    "        # Update tracker.\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "\n",
    "        # Update visualization.\n",
    "        if display:\n",
    "            ax1 = fig.add_subplot(111, aspect='equal')\n",
    "            # fn = 'mot_benchmark/%s/%s/img1/%06d.jpg'%(phase,seq,frame)\n",
    "            ax1.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            plt.title(' Tracked Targets')\n",
    "\n",
    "        # Store results.\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "            bbox = track.to_tlwh()\n",
    "            results.append([\n",
    "                frame_idx, track.track_id, bbox[0], bbox[1], bbox[2], bbox[3]])\n",
    "\n",
    "         \n",
    "            if (display):\n",
    "                ax1.add_patch(patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], fill=False, lw=3,ec=colours[track.track_id % 32, :]))\n",
    "                ax1.set_adjustable('box-forced')\n",
    "                plt.text(bbox[0], bbox[1], str(track.track_id))\n",
    "\n",
    "        if(display):\n",
    "            fig.canvas.flush_events()\n",
    "            plt.draw()\n",
    "            ax1.cla()\n",
    "\n",
    "        if grabbed == False:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
